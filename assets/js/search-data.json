{
  
    
        "post0": {
            "title": "Rust Async",
            "content": ". Some definitions . . green threads: threads scheduled by vm or runtime | native threads are scheduled by os | runtime: the env where your code runs and the libraries it has access to (e.g. jvm, stdlib, malloc). | . . Why use async over OS-provided threads . . native threads are expensive | the async runtime creates its own green threads from the os/kernel and schedules access to them | it handles keeping track of the state of async functions | . “It is registering incoming Future requests and saves a pointer to the async function handler. It then triggers an event in the kernel. Once the I/O operation is done, we call the pointer and execute the async method with the results from the I/O (kernel). For this, we need a Reactor, which notifies if data is coming over the network or a file writing operation is in progress, and an executor which takes this data and executes the async function (Future) with it.” . . https://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/ (outdated?) | . “You can wait() on a Future, which will block until you have a result, and you can also poll() it, asking it if it’s done yet (it will give you the result if it is).” . “You have to manually set up the Tokio event loop (the “scheduler”), but once you do you can feed it tasks which intermittently do I/O, and the event loop takes care of swapping over to a new task when one is blocked on I/O” . Resouces . https://manishearth.github.io/blog/2018/01/10/whats-tokio-and-async-io-all-about/ | https://rust-lang.github.io/async-book/01_getting_started/01_chapter.html | https://levelup.gitconnected.com/explained-how-does-async-work-in-rust-c406f411b2e2 | https://softwareengineering.stackexchange.com/questions/304427/what-really-is-the-runtime-environment | https://areweasyncyet.rs/ | http://www.arewewebyet.org/ | https://tokio.rs/ | .",
            "url": "https://bkkaggle.github.io/blog/rust/2020/08/14/rust-async.html",
            "relUrl": "/rust/2020/08/14/rust-async.html",
            "date": " • Aug 14, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Pytorch Zoo",
            "content": "I originally wrote this blog post for the PyTorch blog which is available here (Use this link to access my article with my friend link so you don’t need to worry about Medium paywalling my article) . . PyTorch Zoo is a collection of modules and utilities that I’ve found to be useful when working on machine learning projects and competitions. PyTorch Zoo contains several modules not available in PyTorch, like cyclical momentum and squeeze-and-excitation, as well as useful utilities like the ability to send notifications and set random seeds to get consistent results. PyTorch Zoo is meant to provide high-quality reference implementations of modules that don’t have official implementations in PyTorch and save you time that would have otherwise been spent searching for implementations on Github or coding the module yourself. . . &lt;/img&gt; . From: https://github.com/bkkaggle/pytorch_zoo . . The library is open-source on Github and is available as a pip package. Just run: . pip install pytorch_zoo . to install it in your local development environment and check out the documentation for in-depth examples on all the library’s features. I’ve included quite a few modules in PyTorch Zoo, so I’ll try to focus only on some of the ones that I found to be the most interesting for this blog post. . . Cyclical Momentum . . Cyclical momentum, which was first proposed in the same paper as cyclical learning rates 1, is usually used together with cyclical learning rates. It decreases the amount of momentum while the learning rate increases and increases the amount of momentum while the learning rate decreases, stabilizing training and allowing for the use of higher learning rates. Here’s an example of how you could use cyclical momentum just like a normal PyTorch scheduler: . optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) scheduler = torch.optim.CyclicMomentum(optimizer) data_loader = torch.utils.data.DataLoader(...) for epoch in range(10): for batch in data_loader: scheduler.batch_step() train_batch(...) . . Squeeze and Excitation . . Squeeze and Excitation modules 2 3 can be easily integrated into existing models by just adding one of these modules after each convolutional block and improves the model’s performance without significantly impacting training time. All three variants of the squeeze-and-excitation block that were proposed in the original papers are available in PyTorch Zoo, see the documentation for specific examples on how to use each one. Here’s an example of how you could use SqueezeAndExcitation in a convolutional block . class Encoder(nn.Module): def __init__(self, in_ch, out_ch, r): super(Encoder, self).__init__() self.conv = nn.Conv2d(in_ch, out_ch, 3, padding=1) self.se = SqueezeAndExcitation(out_ch, r) def forward(self, x): x = F.relu(self.conv(x), inplace=True) x = self.se(x) return x . . Utilities . . PyTorch Zoo also has a small range of utilities to make it easier to follow PyTorch best practices when doing things like saving a model to disk and setting random seeds, as well as easy to use one-liners to do things like sending push notifications when a training run ends. . Here’s an example of how you could use some of these utilities: . # Send a notification to your phone directly with IFTTT (https://ifttt.com/) notifying # you when a training run ends or at the end of an epoch. notify({&#39;value1&#39;: &#39;Notification title&#39;, &#39;value2&#39;: &#39;Notification body&#39;}, key=[IFTTT_KEY]) # Automatically set random seeds for Python, numpy, and Pytorch to make sure your results can be reproduced seed_envirionment(42) # Print how much GPU memory is currently allocated gpu_usage(device, digits=4) # GPU Usage: 6.5 GB # Print out the number of parameters in a Pytorch model print(n_params(model)) # 150909673 # Save a model for a particular cross-validation fold to disk save_model(model, fold=0) . . Conclusion . . To learn more about PyTorch Zoo and its features, check out our Github repository. . The project is still a work in progress, so if you find a bug, think there is something missing, or have any suggestions for new features or modules, feel free to open an issue or a pull request. Feel free to use the library or code from it in your own projects, and if you feel that some code used in this project hasn’t been properly accredited, please open an issue. . . References . . https://arxiv.org/abs/1803.09820 &#8617; . | https://arxiv.org/abs/1709.01507 &#8617; . | https://arxiv.org/abs/1803.02579 &#8617; . |",
            "url": "https://bkkaggle.github.io/blog/ai/cross-posts/2020/04/30/pytorch-zoo.html",
            "relUrl": "/ai/cross-posts/2020/04/30/pytorch-zoo.html",
            "date": " • Apr 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Perplexity",
            "content": "Updated on Aug 2, 2020: Add link to more resources . . Purpose . . The purpose of these series of blog posts is to be a place to store my (still in-progress!) notes about topics in learning, help me keep track of everything I’ve learned over the last three years, and to practice my Latex skills. . This is my second blog post in the series, and this time I’m taking notes on evaluation metrics in NLP. . Most of the content of this post comes from Chip Huyen’s really good article in The Gradient on Evaluation methods for language models and the Deep Learning book, so a big thank you to the authors and editors for making this perplexing (pun intended) topic easy to understand. . let me be 100% clear here, I don’t want to come across like I’m taking someone else’s ideas and publishing them as my own. The purpose of this blog post is to take notes for myself so I can come back to this when I inevitably forget how to calculate perplexity. . Also, take a look at this for another good look at perplexity and the effect of tokenization on it. . . Background . . Language models like GPT2 try to predict the next word (or subword/character, we’ll use the term token in this blog post), in a context of tokens. . For example, when predicting the next word in the sentence &quot;I am a computer science and machine learning&quot;, the probability of the next work being enthusiast could be represented by . P(enthusiast∣I am a computer science and machine learning)P(enthusiast | I space am space a space computer space science space and space machine space learning)P(enthusiast∣I am a computer science and machine learning) . The probability of a sentence $s$, where $s$ is a sequence of n tokens $(w_{0}, w_{1}, … w_{n})$ can be represented as . P(s)=∏i=1np(wi∣w1...wi−1)P(s) = prod_{i = 1}^{n} p(w_i | w_1 ... w_{i-1})P(s)=i=1∏n​p(wi​∣w1​...wi−1​) . expanded, it looks like this: . P(s)=p(w1)p(w2∣w1)p(w3∣w1,w2)...p(wn∣w1w2...wn−1)P(s) = p(w_{1})p(w_{2} | w_{1})p(w_{3} | w_{1}, w_{2})...p(w_{n} | w_{1} w_{2} ... w_{n - 1})P(s)=p(w1​)p(w2​∣w1​)p(w3​∣w1​,w2​)...p(wn​∣w1​w2​...wn−1​) . . Information Theory . . The amount of information given by a discrete event $x$ is calculated by the Self-Information equation 1 . I(x)=−log P(x)I(x) = -log space P(x)I(x)=−log P(x) . Information is normally written in one of two units, $nats$, in which case the logarithm has a base of $e$ or $bits$, with a base of $2$. . One $nat$ encodes the “amount of information gained by observing an event with a probability of $ frac {1} {e}$.” 1 . . Shannon Entropy . . Shannon entropy is the extension of the Self-Information equation to probability distributions and is a way to “quantify the amount of uncertainty in an entire probability distribution.” 1 . H(x)=Ex∼P[log P(x)]H(x) = mathbb E_{x sim P} [log space P(x)]H(x)=Ex∼P​[log P(x)] . It’s a measure of how much information, on average is produced for each letter of a language 2 and (if calculated in units of $bits$) can also be defined as the average number of binary digits required to encode each letter in a vocabulary. . In NLP, the evaluation metric, Bits-per-character (BPC), is really just the entropy of a sequence, calculated with units of bits instead of nats. . Entropy calculated across language models that are trained over different context lengths aren’t exactly comparable, LMs with a longer context len will have more information from which to predict the next token. For example, given the sentence I work with machine learning it should be easier for a LM to predict the next word in the sequence I work with machine, than with just the first word: I. (This is actually a major pain point when I was trying to reproduce gpt2’s ppl numbers on wikitext2 and wikitext103, it’s still unclear how the paper evaluated the ppl values on the tests sets for both datasets.) . . Perplexity . . Perplexity: A measurement of how well a probability distribution or probability model predicts a sample 3 . Perplexity is usually calculated with units of $nats$, so calculate it with the equation: $PPL = e^{loss}$ . . Dealing with different tokenization schemes . . If you want to convert the perplexity between models that have been trained using different tokenization schemes and have a different number of tokens that the LM can predict, multiply the cross-entropy loss of the first language model by the ratio of $( text{n tokens first model} / text{n tokens seconds model})$ . The adjusted perplexity value can be found with 4 : . adj_ppl=eloss∗(#tokens/#tokens for other model)adj _ppl = e^{loss * ( text{ #tokens} / text{ #tokens for other model})}adj_ppl=eloss∗(#tokens/#tokens for other model) . . References . . Chapter 3, Deep Learning, Ian Goodfellow, Yoshua Bengio and Aaron Courville, 2016, MIT Press &#8617; &#8617;2 &#8617;3 . | Claude E Shannon. Prediction and entropy of printed english. Bell system technical journal, 30(1):50–64, 1951. &#8617; . | https://en.wikipedia.org/wiki/Perplexity &#8617; . | https://github.com/NVIDIA/Megatron-LM/blob/master/evaluate_gpt2.py#L282 &#8617; . |",
            "url": "https://bkkaggle.github.io/blog/notes/2020/04/16/perplexity.html",
            "relUrl": "/notes/2020/04/16/perplexity.html",
            "date": " • Apr 16, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "What Is Ai",
            "content": "Google Doc . This was originally a report I made for my ELA class that I’ve formatted into a blog post. Since I had to create the report in a specific way for the assignment, some of the information here has isn’t really relevant to most people who would be reading this blog post and is less technical. . Artificial Intelligence, or as it’s more commonly known, AI, has been said to either transform our world into a utopia, or bring about our doom. With so many widely publicized news stories about AI systems that can generate convincingly human-like text, defeat world champions at board games that were previously thought to be too hard for a computer, or generate images of human faces that appear indistinguishable from the real things, it can seem that we are close to a point at which AI may become self-aware and pose a threat to humans. . To truly understand if these fears of AI surpassing human intelligence and taking over the world are justified, we must first know, what is AI? . What is AI? What is AI? For some, it conjures up pictures from movies like Terminator and The Matrix, of robots gaining sentience and taking over the world. The term “Artificial Intelligence” was coined in 1956, by computer scientist John McCarthy, who, in his article, defines AI as “The science and engineering of making intelligent machines, especially computer programs” 1. Other people define AI in similar terms, saying that “AI is a collection of methods and ideas for building software that can do some of the things that humans can do with their brains” 2. . What is the history of AI? The field of AI started in the years after the end of World War II. In 1947, the famous British mathematician and code-breaker Alan Turing gave a lecture on programming computers to develop intelligent machines 1. Turing was also the creator of the Turing test, a test to determine “a machine’s ability to exhibit intelligent behavior similar to that of a human.” . In the 1960s, researchers at MIT developed a chatbot (a chatbot is a computer program that attempts to carry on a conversation with a human) called ELIZA which was able to pass the Turing test and show that it is possible for a computer program to create human-like text. . In the 1970s and 80s, neural networks, a family of algorithms that are loosely based on the neurons in a human brain, were developed. Neural networks excelled at learning patterns from large amounts of data and were used to automate tasks like reading addresses from envelopes. . In the 1990s and 2000s more progress was made in solving large problems in AI. In 1996, IBM’s Deep Blue computer beat the world’s best chess player, and in 2000, Honda released ASIMO, a humanoid robot that was capable of walking and recognizing objects and gestures. . In 2010, IBM’s Watson computer beat the best human competitors on the trivia game show Jeopardy!. Since around 2012, a lot of AI research is being done in machine learning - deep learning in particular. Deep learning involves stacking layers of neural networks on top of each other to create “deep” neural networks. Neural networks are now used in most of the widely used AI applications today - digital assistants like Siri and Alexa, self-driving cars, and recommendation algorithms from Netflix, Youtube, and other social media companies are all using neural networks in some part. Neural networks currently work better than other AI techniques in many areas because of their ability to learn from large amounts of data and because of the increasing amount of computational power available to train them 3 . . What are the different types of AI? AI is not one single area of research, it consists of many different branches that each have different views on how to build artificially intelligent systems. There are two main types of artificial intelligence, narrow AI and general AI. 2 . Most of the advances in AI have been in narrow AI: getting computers to learn how to do certain tasks as good as or better than a human. Although computers can now do certain tasks better than humans, narrow AI systems are highly specialized - a system designed for classifying images can’t be used to control a robot arm 2 . One example of a branch of narrow AI would be Machine Learning, or ML. Machine learning involves teaching a computer to iteratively learn to solve a task by giving it a large amount of data to learn from. In this way, machine learning lets computers learn how to do tasks without explicitly giving it instructions on how to do so 3 . . General AI involves computers that can generalize to a wide variety of tasks like humans do. So far, there has been very little progress on developing general AI, so any general AI systems are very likely decades away, if not more. 2 . In what areas is AI being used? AI is being used by researchers in a wide variety of areas and for a wide variety of purposes. AI is being used in healthcare to predict the spread of the Coronavirus epidemic, predict with radiologist-level accuracy whether a person has cancer from an x-ray scan, and to more accurately predict the folded structure of proteins, which is a crucial step in designing new life-saving medicines. . AI is also being used by companies in three main ways. First, AI is being used for RPA (Robotic Process Automation), automating time-consuming administrative tasks like transferring data from emails to spreadsheets and databases. Second, AI is being used to gain cognitive insights (which involves using algorithms to “detect patterns in vast volumes of data and interpret their meaning”) by predicting what items customers will buy next and identifying credit card fraud in real time. Finally, AI is being used for cognitive engagement (using AI to engage with potential customers) with chatbots providing customer service at any time and creating customized care plans. 4 . Conclusion Artificial intelligence today is limited to computers that can do certain tasks, sometimes as good as or even better than what a human could do, but highly specialized and limited to the scope of the task that it was trained to do. Once one knows the limitations of AI as we have it today, the claims that AI is close to surpassing human intelligence and taking over the world seem unfounded. . Footnotes . http://jmc.stanford.edu/articles/whatisai/whatisai.pdf &#8617; &#8617;2 . | https://www.skynettoday.com/editorials/ai-coverage-best-practices &#8617; &#8617;2 &#8617;3 &#8617;4 . | https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/ &#8617; &#8617;2 . | Davenport, Thomas H and Ronanki, Rajeev. “Artificial Intelligence for the real world.” Harvard Business Review. January-February 2018: Pages 110 and 112 &#8617; . |",
            "url": "https://bkkaggle.github.io/blog/ai/non-technical/2020/03/22/what-is-ai.html",
            "relUrl": "/ai/non-technical/2020/03/22/what-is-ai.html",
            "date": " • Mar 22, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://bkkaggle.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Template",
            "content": "",
            "url": "https://bkkaggle.github.io/blog/2020/01/14/template.html",
            "relUrl": "/2020/01/14/template.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Check out my website for more about me. .",
          "url": "https://bkkaggle.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://bkkaggle.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}